{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import Yukawa_SINDy as ys\n",
    "import pysindy as ps\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included to update Yukawa_SINDy.py version used in this notebook as changes are made\n",
    "reload(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.autolimit_mode'] = 'data'\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['figure.figsize'] = (8,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c2165",
   "metadata": {},
   "source": [
    "list of functions exported to 'Yukawa_SINDy.py'\n",
    "\n",
    "- `generate_training_data`\n",
    "- `plot_complexities`\n",
    "- `scan_thresholds`\n",
    "- `generate_libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsim = ys.Yukawa_simulation()\n",
    "testsim.simulate(3, 0.001, 0.5,0.01,scaled=True)\n",
    "testsim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = testsim.x[:,0]\n",
    "avg_pos = np.average(np.abs(positions))\n",
    "rms_pos = np.sqrt(np.sum(positions**2) / len(positions))\n",
    "print(\"avg position:\", avg_pos)\n",
    "print(\"rms position:\", rms_pos)\n",
    "velocities = testsim.x[:,1]\n",
    "avg_vel = np.average(np.abs(velocities))\n",
    "rms_vel = np.sqrt(np.sum(velocities**2) / len(velocities))\n",
    "print(\"avg velocity:\", avg_vel)\n",
    "print(\"rms velocity:\", rms_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804be64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise and calculate signal-to-noise ratio (SNR) using avg positions\n",
    "noise_level = 0.01\n",
    "testsim.add_gaussian_noise(noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_pos = avg_pos / noise_level\n",
    "SNR_pos_dB = 10*np.log10(SNR_pos)\n",
    "print(\"position SNR (dB):\", SNR_pos_dB)\n",
    "SNR_vel = avg_vel / noise_level\n",
    "SNR_vel_dB = 10*np.log10(SNR_vel)\n",
    "print(\"velocity SNR (dB):\", SNR_vel_dB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb5272",
   "metadata": {},
   "source": [
    "# Analysis of Yukawa 2-body data using Weak SINDy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb456395",
   "metadata": {},
   "source": [
    "In order to tie the simulation to real a dusty plasma system we normalize space and time according to the electron Debye length (`lambda_De` or $\\lambda_{De}$, the relevant Yukawa screening length) and the plasma *dust* frequency in Hertz (`f_pd` or $f_{pd}$). These quantities are calculated below. The \"scaling constant\" comes from collecting all these values from the normalizations along with any constants in the equation of motion, so\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    m_d\\frac{d^2r}{dt^2}=\\frac{q_d^2}{4\\pi\\varepsilon_0}\n",
    "    \\left[\n",
    "        \\frac{e^{-r/\\lambda_{De}}}{\\lambda_{De}r} + \\frac{e^{-r/\\lambda_{De}}}{r^2}\n",
    "    \\right],\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $m_d$ is the mass of the dust, $r$ is the interparticle spacing, and $q_d$ is the dust charge, becomes\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\frac{d^2\\hat{r}}{(dt^{*})^2}=A\n",
    "    \\left[\n",
    "        \\frac{e^{-\\hat{r}}}{\\hat{r}} + \\frac{e^{-\\hat{r}}}{\\hat{r}^2}\n",
    "    \\right],\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\hat{r}=r/\\lambda_{De}$, $t^*=f_{pd}t$, and $A=\\frac{q_d^2}{4\\pi\\varepsilon_0 m_d f_{pd}^2 \\lambda_{De}^3}$ is what we refer to as the \"scaling constant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c075399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling constant\n",
    "ep_0 = 8.85e-12 # epsilon naught\n",
    "m_d = 3.03e-14  # dust mass in kg\n",
    "mu = m_d / 2    # reduced mass\n",
    "n_d = 1e11      # dust density in m^-3\n",
    "n_e = 2.81e14   # electron density in m^-3\n",
    "e = 1.60e-19    # fundamental charge in Coulombs\n",
    "q_d = 1e4 * e   # dust charge\n",
    "kT_e = 1.24e-18 # in Joules (converted from eV)\n",
    "\n",
    "lambda_De = ( ( ep_0 * kT_e ) / ( n_e * e**2 ) )**(1/2)\n",
    "omega_pd = np.sqrt( ( n_d * q_d**2 ) / ( ep_0 * m_d ) )\n",
    "f_pd = omega_pd / (2 * np.pi)\n",
    "\n",
    "A = q_d**2 / (4 * np.pi * ep_0 * mu * lambda_De**3 * f_pd**2)\n",
    "print(\"scaling constant:\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_De"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819aa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_dim = 14e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1838b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_De / px_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5a920",
   "metadata": {},
   "source": [
    "We can interpret this scaling constant as proportional to a ratio of energies, particularly the electrostatic Coulomb potential energy and the electron thermal kinetic energy. We show this here:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    A &= \\frac{q_d^2}{4\\pi\\varepsilon_0\\lambda_{De}} \\frac{1}{m_d f_{pd}^2\\lambda_{De}^2} \\\\\n",
    "      &= \\frac{q_d^2}{4\\pi\\varepsilon_0\\lambda_{De}} \\frac{1}{m_d} \\frac{2\\pi\\varepsilon_0 m_d}{n_d q_d^2} \\frac{n_e e^2}{\\varepsilon_0 k_B T_e} \\\\\n",
    "      &= \\frac{q_d^2}{4\\pi\\varepsilon_0\\lambda_{De}} 2\\pi\\frac{n_e}{n_d Z_d^2}\\frac{1}{k_B T_e} \\\\\n",
    "      &= 2\\pi \\frac{q_d^2}{4\\pi\\varepsilon_0\\lambda_{De}} \\frac{1}{k_B T_e}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $k_B$ is the Boltzmann constant, $e$ is the fundamental charge, $Z_d=\\frac{q_d}{e}$, and we used quasineutrality $n_e=Z_d n_d + n_i$ to cancel out the ratio of densities (probably not lol????) in  so\n",
    "$$\n",
    "\\begin{equation*}\n",
    "  A \\propto \\frac{\\epsilon_{C,d}}{\\epsilon_{th,e}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "with $\\epsilon_{C,d}=\\frac{q_d^2}{4\\pi\\varepsilon_0\\lambda_{De}}$ and $\\epsilon_{th,e}=k_B T_e$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ab0b8",
   "metadata": {},
   "source": [
    "## `std_dev=0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1832a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set var 'noise_level' for this section\n",
    "noise_level = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516fdc1",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a weak SINDy analysis on 2-body trajectories to see if the sparse recovery of simulation coefficients is improved. Results from the analysis of the same system using only one trajectory with strong-form SINDy (the original formulation) is shown in the notebook 'Yukawa2body.ipynb'.\n",
    "\n",
    "Here, we will start by using one trajectory of the 2-body equations, as we did before, and then possibly extend to more trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c62f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim001 = ys.Yukawa_simulation()\n",
    "sim001.simulate(5, dt=0.001, x0=0.5, v0=0.01, scaled=True)\n",
    "sim001.add_gaussian_noise(noise_level=noise_level)\n",
    "sim001.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, A, 0.05*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim001, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbad5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d10931",
   "metadata": {},
   "source": [
    "the model is fit at `threshold=0.35*A` to a very good approximation with the weak formulation. In this parameter range, the strong form does not really come close to the correct equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 10*A, 0.5*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim001, thresholds, verbose=True)\n",
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c1618",
   "metadata": {},
   "source": [
    "From this, we can see that strong form discovers nothing meaningful, even when the threshold is at $10A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f87def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to be used for spot checking whatever threshold\n",
    "threshold = 0.35*A\n",
    "opt = ps.STLSQ(threshold=threshold)\n",
    "weak_lib, strong_lib = ys.generate_libraries(sim001.t)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"], feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(sim001.x)\n",
    "weak_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56bef4",
   "metadata": {},
   "source": [
    "## `std_dev=0.10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eeec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim010 = ys.Yukawa_simulation()\n",
    "sim010.simulate(5, dt=0.001,x0=0.5,v0=0.01,scaled=True)\n",
    "sim010.add_gaussian_noise(noise_level=noise_level)\n",
    "sim010.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255eab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 2*A, 0.2*A)\n",
    "print(thresholds)\n",
    "print(thresholds/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1*A, 0.02*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim010, thresholds, verbose=True)\n",
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bad081",
   "metadata": {},
   "source": [
    "With a single trajectory, WSINDy does not recover the correct equations of motion, but it does discover the leading terms along with the presence of extraneous terms. This improves with the multiple trajectories approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cead34e",
   "metadata": {},
   "source": [
    "## Multiple trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e5158",
   "metadata": {},
   "source": [
    "We can also generate many trajectories with different initial conditions and use that to train SINDy. This is what we were already doing for the three-body case, but we can see how much it improves the performance of SINDy here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea694083",
   "metadata": {},
   "source": [
    "Note that we generate random initial conditions in the following way:\n",
    "\n",
    "- *Initial positions*: taken from a normal distribution centered at 1 with std. dev. of 0.2\n",
    "- *Initial velocities*: taken from a normal distribution centered at 0.01 with a std. dev. of 0.002, also with a random +/- sign.\n",
    "\n",
    "This was done carefully so as to avoid there being zeros in the initial conditions, which create problems for the solver and for SINDy because of the presence of the rational terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d5e25",
   "metadata": {},
   "source": [
    "### `noise_level=0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'noise_level' back to 0.01\n",
    "noise_level = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb793527",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims001 = ys.generate_training_data(noise_level=noise_level, scaled=True, mu_x0s=0.5)\n",
    "sims001[73].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims001[100].is_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 0.2*A, 0.01*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sims001, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678280",
   "metadata": {},
   "source": [
    "So the \"correct model\" is discovered by the weak form when `threshold=0.04*A` with no small extraneous terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds,complexities, noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb8df1",
   "metadata": {},
   "source": [
    "### `noise_level=0.10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims010 = ys.generate_training_data(noise_level=noise_level, mu_x0s=0.5, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims010[38].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = np.arange(0, 0.2, 0.01)\n",
    "thresholds = np.concatenate((np.arange(0, 0.2*A, 0.01*A), np.arange(0.2*A, 1.0*A, 0.05*A), np.arange(1.0*A, 5.0*A, 0.5*A)))\n",
    "libs = ys.generate_libraries(sims010[0].t)\n",
    "x_train010 = [sim.x for sim in sims010]\n",
    "t_train010 = sims010[0].t\n",
    "thresholds, complexities = ys.scan_thresholds(sims010, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818015a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd942dc",
   "metadata": {},
   "source": [
    "Noticing as these models are coming out that there is a long series of the exact same models between 0.05 and 0.18 in the weak case, with a few steps happening for the strong models. \n",
    "It might be interesting to look into an optimal threshold step size that would minimize SINDy discovering the same model over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [sim.x for sim in sims010] # if sim.x.shape[0] == 5000]\n",
    "t_train = sims010[0].t\n",
    "weak_lib, strong_lib = generate_libraries(t_train)\n",
    "opt = ps.STLSQ(threshold=0.5)\n",
    "strong_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=strong_lib, optimizer=opt)\n",
    "strong_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "strong_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ps.STLSQ(threshold=0.2)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "weak_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad3ab8",
   "metadata": {},
   "source": [
    "The weak form of SINDy discovers the correct underlying model with a threshold of 0.2, while strong-form SINDy does not discover the correct model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d8d32",
   "metadata": {},
   "source": [
    "### `noise_level=0.20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1cd73",
   "metadata": {},
   "source": [
    "### `noise_level=0.50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for spot-checking weak models\n",
    "x_train = [sim.x for sim in sims050]\n",
    "t_train = sims050[0].t\n",
    "\n",
    "weak_lib, strong_lib = generate_libraries(t_train)\n",
    "opt = ps.STLSQ(threshold=0.0001)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "weak_model.print(precision=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
