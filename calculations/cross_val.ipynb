{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to be repo base\n",
    "import os\n",
    "os.chdir('/Users/zbh0005/Library/CloudStorage/OneDrive-AuburnUniversity/Documents/Code/yukawa-sindy')\n",
    "# import function file\n",
    "import Yukawa_SINDy as ys\n",
    "# import libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "import pysindy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "# ignore warnings generated from using LaTeX coding in matplotlib label strings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', message = 'invalid escape sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199'],\n",
    "              ['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199']]).T\n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(X):\n",
    "    print('train:', X[train])\n",
    "    print('test:', X[test])\n",
    "    print(60*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199']\n",
    "              \n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(X):\n",
    "    for idx in train:\n",
    "        print('train:', X[idx])\n",
    "    for idx in test:\n",
    "        print('test:', X[idx])\n",
    "    print(60*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(train,test)\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = ys.generate_training_data(noise_level=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_times(list_of_sims:list):\n",
    "    '''\n",
    "    Description: Helper function to check if all simulations in a list of \n",
    "    Yukawa_SINDy.Yukawa_simulation objs have the same time grid. returns \n",
    "    True or False.\n",
    "    '''\n",
    "    same_times:bool = True\n",
    "    t_check = list_of_sims[0].t\n",
    "    for sim in list_of_sims[1:]:\n",
    "        if not np.all(t_check == sim.t):\n",
    "            same_times = False\n",
    "            break\n",
    "    return same_times\n",
    "\n",
    "\n",
    "def kfold_training(x_train:np.ndarray, t_data:np.ndarray, n_folds:int, n_features:int):\n",
    "    # check dimension of training_data and t_data arrays\n",
    "    if x_train.ndim!=3:\n",
    "        raise Exception('training data has wrong dimensions')\n",
    "    if x_train.shape[1]!=t_data.shape[0]:\n",
    "        raise Exception('time data has wrong dimensions')\n",
    "    \n",
    "    # perform KFold CV\n",
    "    all_rmse = np.array([])\n",
    "    all_coefs = np.empty((0,x_train.shape[2],n_features))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train, test in kf.split(x_train):\n",
    "        # split training data\n",
    "        x_train_kf = [traj for traj in x_train[train]]\n",
    "        x_test_kf  = [traj for traj in x_train[test]]\n",
    "        # print(f'x_train_kf len and shape of one traj: {len(x_train_kf)}, {x_train_kf[4].shape}')\n",
    "        # fit SINDy model using given threshold\n",
    "        mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "        mdl.fit(x_train_kf, t_data, multiple_trajectories=True)\n",
    "        mdl.print()\n",
    "\n",
    "        # get coefs and append to all_coefs\n",
    "        coefs = mdl.coefficients()\n",
    "        coefs = coefs.reshape((1,*coefs.shape))\n",
    "        all_coefs = np.vstack((all_coefs,coefs))\n",
    "\n",
    "        # validate model against test data\n",
    "        # print(f'test traj shape: {x_test_kf[0].shape}') # included for testing\n",
    "        # print(f'coefficients shape: {mdl.coefficients().shape}') # included for testing\n",
    "        rmse = mdl.score(x_test_kf, t=t_data, multiple_trajectories=True, metric=root_mean_squared_error)\n",
    "        all_rmse = np.hstack((all_rmse, rmse))\n",
    "\n",
    "        # # old code\n",
    "        # x_dot_predicted = mdl.predict(x_test_kf)\n",
    "        # fd = ps.FiniteDifference()\n",
    "        # x_dot_calculated = fd._differentiate(x_test_kf)\n",
    "        # rmse = root_mean_squared_error(x_dot_calculated, x_dot_predicted)\n",
    "        # rmse_kf.append(rmse)\n",
    "    \n",
    "    return all_rmse, all_coefs\n",
    "\n",
    "\n",
    "def cross_validate(all_data:list, threshold:float, feature_library, feature_names, n_folds=10):\n",
    "    '''\n",
    "    Description: This function performs k-fold cross-validation (cv) with k specified by the 'n_folds'\n",
    "    (default 10) argument. Gets help from the 'sklearn.model_selection.KFold' object. Takes a list \n",
    "    of Yukawa_SINDy.Yukawa_simulation objects, a SINDy STLSQ threshold, a feature library \n",
    "    ('pysindy.BaseFeatureLibrary' child objs), and feature names as args. Returns a rank 3 numpy\n",
    "    array of coefficients from the best two models: the one with the lowest error and the average\n",
    "    coefficients of all models generated during k-fold cv.\n",
    "    '''\n",
    "    # check if list of sim objects\n",
    "    for item in all_data:\n",
    "        if not isinstance(item, ys.Yukawa_simulation):\n",
    "            raise TypeError(\"Argument 'all_data' should be list of 'Yukawa_SINDy.Yukawa_simulation' objects\")\n",
    "    # check if all time grids are the same\n",
    "    if not same_times(all_data):\n",
    "        raise Exception(\"All simulations do not have the same time grid.\")\n",
    "    \n",
    "    # extract data from sim objects\n",
    "    x_data = np.array([sim.x for sim in all_data])\n",
    "    t_data = sims[0].t\n",
    "    n_timesteps = t_data.shape[0]\n",
    "    # print(f'shape and ndims of t_data: {t_data.shape}, {t_data.ndim}') # included for testing\n",
    "\n",
    "    # split data into withhold(testing) and training data\n",
    "    n_trajectories = len(all_data)\n",
    "    rng = np.random.default_rng(seed=10235783)\n",
    "    withhold_idxs = rng.choice(x_data.shape[0], np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "    withhold_idxs.sort()\n",
    "    train_idxs = np.delete(np.arange(len(all_data)), withhold_idxs)\n",
    "    x_train = x_data[train_idxs]\n",
    "    x_withhold = x_data[withhold_idxs]\n",
    "\n",
    "    # declare optimizer with given threshold\n",
    "    opt = ps.STLSQ(threshold=threshold)\n",
    "\n",
    "    # get number of terms in library\n",
    "    rand_data = np.random.random((5000,2))\n",
    "    test_mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "    test_mdl.fit(rand_data)\n",
    "    feature_list = test_mdl.get_feature_names()\n",
    "    n_features = len(feature_list)\n",
    "    del test_mdl, rand_data\n",
    "\n",
    "\n",
    "\n",
    "    return x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "feature_library = ys.generate_Yukawa_library()\n",
    "feature_names = ['x', 'v']\n",
    "\n",
    "x_train = cross_validate(sims, threshold, feature_library, feature_names)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_KFold(X):\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train, test in kf.split(X):\n",
    "        print(f'training set shape: {X[train].shape}')\n",
    "        print(f'testing set shape: {X[test].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_KFold(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "feature_library = ys.generate_Yukawa_library()\n",
    "feature_names = ['x', 'v']\n",
    "\n",
    "x_train, x_withhold = cross_validate(sims, threshold, feature_library, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_times(list_of_sims:list):\n",
    "    '''\n",
    "    Description: Helper function to check if all simulations in a list of \n",
    "    Yukawa_SINDy.Yukawa_simulation objs have the same time grid. returns \n",
    "    True or False.\n",
    "    '''\n",
    "    same_times:bool = True\n",
    "    t_check = list_of_sims[0].t\n",
    "    for sim in list_of_sims[1:]:\n",
    "        if not np.all(t_check == sim.t):\n",
    "            same_times = False\n",
    "            break\n",
    "    return same_times\n",
    "\n",
    "\n",
    "def kfold_training(training_data:np.ndarray, n_folds:int, n_features:int):\n",
    "    # check dimension of training_data array\n",
    "    if training_data.ndim!=3:\n",
    "        raise Exception(\"training data has wrong dimensions\")\n",
    "    \n",
    "    # perform KFold CV\n",
    "    rmse_kf = []\n",
    "    all_coefs = np.empty((0,training_data.shape[2],n_features))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train, test in kf.split(train_idxs):\n",
    "        # split training data\n",
    "        x_train_kf = [traj for traj in x_train[train]]\n",
    "        x_test_kf  = [traj for traj in x_train[test]]\n",
    "        # print(f'x_train_kf len and shape of one traj: {len(x_train_kf)}, {x_train_kf[4].shape}')\n",
    "        # fit SINDy model using given threshold\n",
    "        mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "        mdl.fit(x_train_kf, t_data, multiple_trajectories=True)\n",
    "        mdl.print()\n",
    "\n",
    "        # get coefs and append to all_coefs\n",
    "        coefs = mdl.coefficients()\n",
    "        coefs = coefs.reshape((1,*coefs.shape))\n",
    "        all_coefs = np.vstack((all_coefs,coefs))\n",
    "\n",
    "        # validate model against test data\n",
    "        # print(f'test traj shape: {x_test_kf[0].shape}') # included for testing\n",
    "        # print(f'coefficients shape: {mdl.coefficients().shape}') # included for testing\n",
    "        rmse = mdl.score(x_test_kf, t=t_data, multiple_trajectories=True, metric=root_mean_squared_error)\n",
    "        rmse_kf.append(rmse)\n",
    "\n",
    "        # # old code\n",
    "        # x_dot_predicted = mdl.predict(x_test_kf)\n",
    "        # fd = ps.FiniteDifference()\n",
    "        # x_dot_calculated = fd._differentiate(x_test_kf)\n",
    "        # rmse = root_mean_squared_error(x_dot_calculated, x_dot_predicted)\n",
    "        # rmse_kf.append(rmse)\n",
    "    \n",
    "    return rmse_kf, all_coefs\n",
    "\n",
    "\n",
    "def cross_validate(all_data:list, threshold:float, feature_library, feature_names, n_folds=10):\n",
    "    '''\n",
    "    Description: This function performs k-fold cross-validation (cv) with k specified by the 'n_folds'\n",
    "    (default 10) argument. Gets help from the 'sklearn.model_selection.KFold' object. Takes a list \n",
    "    of Yukawa_SINDy.Yukawa_simulation objects, a SINDy STLSQ threshold, a feature library \n",
    "    ('pysindy.BaseFeatureLibrary' child objs), and feature names as args. Returns a rank 3 numpy\n",
    "    array of coefficients from the best two models: the one with the lowest error and the average\n",
    "    coefficients of all models generated during k-fold cv.\n",
    "    '''\n",
    "    # check if list of sim objects\n",
    "    for item in all_data:\n",
    "        if not isinstance(item, ys.Yukawa_simulation):\n",
    "            raise TypeError(\"Argument 'all_data' should be list of 'Yukawa_SINDy.Yukawa_simulation' objects\")\n",
    "    # check if all time grids are the same\n",
    "    if not same_times(all_data):\n",
    "        raise Exception(\"All simulations do not have the same time grid.\")\n",
    "    \n",
    "    # extract data from sim objects\n",
    "    x_data = np.array([sim.x for sim in all_data])\n",
    "    t_data = sims[0].t\n",
    "    n_timesteps = t_data.shape[0]\n",
    "    print(f'shape and ndims of t_data: {t_data.shape}, {t_data.ndim}')\n",
    "\n",
    "    # split data into withhold(testing) and training data\n",
    "    n_trajectories = len(all_data)\n",
    "    rng = np.random.default_rng(seed=10235783)\n",
    "    withhold_idxs = rng.choice(x_data.shape[0], np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "    withhold_idxs.sort()\n",
    "    train_idxs = np.delete(np.arange(len(all_data)), withhold_idxs)\n",
    "    x_train = x_data[train_idxs]\n",
    "    x_withhold = x_data[withhold_idxs]\n",
    "\n",
    "    # declare optimizer with given threshold\n",
    "    opt = ps.STLSQ(threshold=threshold)\n",
    "\n",
    "    # get number of terms in library\n",
    "    rand_data = np.random.random((5000,2))\n",
    "    test_mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "    test_mdl.fit(rand_data)\n",
    "    feature_list = test_mdl.get_feature_names()\n",
    "    n_features = len(feature_list)\n",
    "    del test_mdl, rand_data\n",
    "\n",
    "    return train_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysindy.utils import lorenz\n",
    "from scipy.integrate import solve_ivp\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-12\n",
    "integrator_keywords['method'] = 'LSODA'\n",
    "integrator_keywords['atol'] = 1e-12\n",
    "\n",
    "def fuckery(n_trajectories:int, duration: float or int, dt=2e-3):\n",
    "    # train a test model\n",
    "    t_train = np.arange(0,duration,dt)\n",
    "    t_train_span = (t_train[0], t_train[-1])\n",
    "    print(f'shape and ndims of t_data: {t_train.shape}, {t_train.ndim}')\n",
    "    x_train = []\n",
    "    for i in range(n_trajectories):\n",
    "        # x0_train = [-8,8,27]\n",
    "        # generate random init cond\n",
    "        rng = np.random.default_rng(seed=293854)\n",
    "        x0_train = 30*rng.random(3)\n",
    "        if i==0:\n",
    "            print(x0_train)\n",
    "        x_train_traj = solve_ivp(lorenz, t_train_span, x0_train, t_eval=t_train, **integrator_keywords).y.T\n",
    "        x_train.append(x_train_traj)\n",
    "    return x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "duration = 10\n",
    "dt = 2e-3\n",
    "x_train = fuckery(75, duration, dt)\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=dt, multiple_trajectories=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "duration = 15\n",
    "x_test = fuckery(25, duration, dt)\n",
    "print(f'model score: {model.score(x_test,t=dt,multiple_trajectories=True):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefs = model.coefficients()\n",
    "coefs = model.coefficients()\n",
    "coefs = coefs.reshape((1,*coefs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coefficients().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coefficients().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate on other trajectory\n",
    "t_test = np.arange(0,15,dt)\n",
    "x0_test = [8,7,15]\n",
    "t_test_span = (t_test[0],t_test[-1])\n",
    "x_test = solve_ivp(lorenz, t_test_span, x0_test, t_eval=t_test, **integrator_keywords).y.T\n",
    "print(f'Model score: {model.score(x_test,t=dt):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate measurement data\n",
    "dt = .002\n",
    "\n",
    "t_train = np.arange(0, 10, dt)\n",
    "x0_train = [-8, 8, 27]\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "x_train = solve_ivp(lorenz, t_train_span, x0_train, \n",
    "                    t_eval=t_train, **integrator_keywords).y.T\n",
    "# Instantiate and fit the SINDy model\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()\n",
    "# Evolve the Lorenz equations in time using a different initial condition\n",
    "t_test = np.arange(0, 15, dt)\n",
    "x0_test = np.array([8, 7, 15])\n",
    "t_test_span = (t_test[0], t_test[-1])\n",
    "x_test = solve_ivp(lorenz, t_test_span, x0_test, \n",
    "                   t_eval=t_test, **integrator_keywords).y.T  \n",
    "\n",
    "# Compare SINDy-predicted derivatives with finite difference derivatives\n",
    "print('Model score: %f' % model.score(x_test, t=dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [[[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]],\n",
    "          [[5,5,5,5],4*[6],4*[7],4*[8]],\n",
    "          [4*[9],4*[10],4*[11],4*[12]]]\n",
    "x = np.array(x_list)\n",
    "np.average(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract data from sim objects\n",
    "x_data = np.array([sim.x for sim in sims])\n",
    "t_data = sims[0].t\n",
    "n_timesteps = t_data.shape[0]\n",
    "\n",
    "# split data into withhold(testing) and training data\n",
    "n_trajectories = len(sims)\n",
    "rng = np.random.default_rng(seed=10235783)\n",
    "withhold_idxs = rng.choice(n_trajectories, np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "withhold_idxs.sort()\n",
    "train_idxs = np.delete(np.arange(len(sims)), withhold_idxs)\n",
    "x_train = x_data[train_idxs]\n",
    "x_withhold = x_data[withhold_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training: {x_train.shape}, withhold: {x_withhold.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = np.empty((0,5000,2))\n",
    "append = np.random.random((5000,2))\n",
    "append.resize((1,5000,2))\n",
    "np.vstack((emp,append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (5,2)\n",
    "b = (10,*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
