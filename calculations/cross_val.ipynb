{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to be repo base\n",
    "import os\n",
    "os.chdir('/Users/zbh0005/Library/CloudStorage/OneDrive-AuburnUniversity/Documents/Code/yukawa-sindy')\n",
    "# import function file\n",
    "import Yukawa_SINDy as ys\n",
    "# import libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "import pysindy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "# ignore warnings generated from using LaTeX coding in matplotlib label strings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', message = 'invalid escape sequence')\n",
    "# import scaling constant from working directory and declare as global variable\n",
    "from pickle import load\n",
    "with open('scaling_const.float','rb') as f:\n",
    "    A = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_times(list_of_sims:list):\n",
    "    '''\n",
    "    Description: Helper function to check if all simulations in a list of \n",
    "    Yukawa_SINDy.Yukawa_simulation objs have the same time grid. returns \n",
    "    True or False.\n",
    "    '''\n",
    "    same_times:bool = True\n",
    "    t_check = list_of_sims[0].t\n",
    "    for sim in list_of_sims[1:]:\n",
    "        if not np.all(t_check == sim.t):\n",
    "            same_times = False\n",
    "            break\n",
    "    return same_times\n",
    "\n",
    "\n",
    "def kfold_training(x_train:np.ndarray, t_data:np.ndarray, n_folds:int, SINDy_model:ps.SINDy, verbose=False):\n",
    "    # check dimension of training_data and t_data arrays\n",
    "    if x_train.ndim!=3:\n",
    "        raise Exception('training data has wrong dimensions')\n",
    "    if x_train.shape[1]!=t_data.shape[0]:\n",
    "        raise Exception('time data has wrong dimensions')\n",
    "    # get SINDy parameters from input SINDy model\n",
    "    feature_list = SINDy_model.get_feature_names()\n",
    "    n_features = len(feature_list)\n",
    "    feature_library = SINDy_model.feature_library\n",
    "    feature_names = SINDy_model.feature_names\n",
    "    opt = SINDy_model.optimizer\n",
    "\n",
    "    # check if feature_library is weak or strong, don't need\n",
    "    # to pass time as an arg into the 'fit' method of ps.SINDy\n",
    "    if isinstance(feature_library, ps.WeakPDELibrary):\n",
    "        t_to_fit = None\n",
    "    else:\n",
    "        t_to_fit = t_data\n",
    "    \n",
    "    # perform KFold CV\n",
    "    all_rmse = np.array([])\n",
    "    all_coefs = np.empty((0,x_train.shape[2],n_features))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train, test in kf.split(x_train):\n",
    "        # split training data\n",
    "        x_train_kf = [traj for traj in x_train[train]]\n",
    "        x_test_kf  = [traj for traj in x_train[test]]\n",
    "        # print(f'train shape: {train.shape}')\n",
    "        # print(f'test shape: {test.shape}')\n",
    "        # fit SINDy model using given threshold\n",
    "        mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "        mdl.fit(x_train_kf, t_to_fit, multiple_trajectories=True)\n",
    "        if verbose: mdl.print()\n",
    "\n",
    "        # get coefs and append to all_coefs\n",
    "        coefs = mdl.coefficients()\n",
    "        coefs = coefs.reshape((1,*coefs.shape))\n",
    "        all_coefs = np.vstack((all_coefs,coefs))\n",
    "\n",
    "        # validate model against test data\n",
    "        # print(f'test traj shape: {x_test_kf[0].shape}') # included for testing\n",
    "        # print(f'coefficients shape: {mdl.coefficients().shape}') # included for testing\n",
    "        rmse = mdl.score(x_test_kf, t=t_data, multiple_trajectories=True, metric=root_mean_squared_error)\n",
    "        all_rmse = np.hstack((all_rmse, rmse))\n",
    "    \n",
    "    return all_rmse, all_coefs\n",
    "\n",
    "\n",
    "def cross_validate(all_data:list, threshold:float, feature_library, feature_names, n_folds=10):\n",
    "    '''\n",
    "    Description: This function performs k-fold cross-validation (cv) with k specified by the 'n_folds'\n",
    "    (default 10) argument. Gets help from the 'sklearn.model_selection.KFold' object. Takes a list \n",
    "    of Yukawa_SINDy.Yukawa_simulation objects, a SINDy STLSQ threshold, a feature library \n",
    "    ('pysindy.BaseFeatureLibrary' child objs), and feature names as args. Returns a rank 3 numpy\n",
    "    array of coefficients from the best two models: the one with the lowest error and the average\n",
    "    coefficients of all models generated during k-fold cv.\n",
    "    '''\n",
    "    # check if list of sim objects\n",
    "    for item in all_data:\n",
    "        if not isinstance(item, ys.Yukawa_simulation):\n",
    "            raise TypeError(\"Argument 'all_data' should be list of 'Yukawa_SINDy.Yukawa_simulation' objects\")\n",
    "    # check if all time grids are the same\n",
    "    if not same_times(all_data):\n",
    "        raise Exception(\"All simulations do not have the same time grid.\")\n",
    "    \n",
    "    # extract data from sim objects\n",
    "    x_data = np.array([sim.x for sim in all_data])\n",
    "    t_data = sims[0].t\n",
    "    n_timesteps = t_data.shape[0]\n",
    "    # print(f'shape and ndims of t_data: {t_data.shape}, {t_data.ndim}') # included for testing\n",
    "\n",
    "    # split data into withhold(testing) and training data\n",
    "    n_trajectories = len(all_data)\n",
    "    rng = np.random.default_rng(seed=10235783)\n",
    "    withhold_idxs = rng.choice(x_data.shape[0], np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "    withhold_idxs.sort()\n",
    "    train_idxs = np.delete(np.arange(len(all_data)), withhold_idxs)\n",
    "    x_train = x_data[train_idxs]\n",
    "    x_withhold = x_data[withhold_idxs]\n",
    "\n",
    "    # declare optimizer with given threshold\n",
    "    opt = ps.STLSQ(threshold=threshold)\n",
    "\n",
    "    # get number of terms in library\n",
    "    rand_data = np.random.random((5000,2))\n",
    "    test_mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "    test_mdl.fit(rand_data)\n",
    "\n",
    "    # perform kfold cv\n",
    "    rmse, coef = kfold_training(x_train,t_data,n_folds,test_mdl)\n",
    "\n",
    "    del test_mdl, rand_data\n",
    "\n",
    "\n",
    "    return rmse, coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = ys.generate_training_data(noise_level=0.01,scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims[77].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold =0.4\n",
    "t_data = sims[0].t\n",
    "weak_lib, strong_lib = ys.generate_libraries(t_data)\n",
    "feature_names = ['x', 'v']\n",
    "\n",
    "rmse, coef = cross_validate(sims, threshold, weak_lib, feature_names)\n",
    "# x_train.shape\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(rmse,'o')\n",
    "ax.set_xlabel(\"Model no.\")\n",
    "ax.set_ylabel(\"Root mean squared error\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mat = np.array( [ 10*[1], 10*[A] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[5]/norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[1]/norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_coefs = np.array( [ [0., 1., 0., 0., 0., 0., 0., 0., 0., 0. ], \n",
    "                            [0., 0., 1., 0., 1., 0., 0., 0., 0., 0. ] ] ).reshape((1,2,10))\n",
    "coef_diff = np.abs(coef/norm_mat - correct_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_diff[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_diff[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_diff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.mean(axis=0)/norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
