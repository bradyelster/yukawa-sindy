{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to be repo base\n",
    "import os\n",
    "os.chdir('/Users/zbh0005/Library/CloudStorage/OneDrive-AuburnUniversity/Documents/Code/yukawa-sindy')\n",
    "# import function file\n",
    "import Yukawa_SINDy as ys\n",
    "# import libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "import pysindy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "# ignore warnings generated from using LaTeX coding in matplotlib label strings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', message = 'invalid escape sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199'],\n",
    "              ['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199']]).T\n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(X):\n",
    "    print('train:', X[train])\n",
    "    print('test:', X[test])\n",
    "    print(60*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['traj0-19', 'traj20-39', 'traj40-59', 'traj60-79', 'traj80-99', 'traj100-119', 'traj120-139', 'traj140-159', 'traj160-179', 'traj180-199']\n",
    "              \n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(X):\n",
    "    for idx in train:\n",
    "        print('train:', X[idx])\n",
    "    for idx in test:\n",
    "        print('test:', X[idx])\n",
    "    print(60*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(train,test)\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = ys.generate_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_times(list_of_sims:list):\n",
    "    '''\n",
    "    Description: Helper function to check if all simulations in a list of \n",
    "    Yukawa_SINDy.Yukawa_simulation objs have the same time grid. returns \n",
    "    True or False.\n",
    "    '''\n",
    "    same_times:bool = True\n",
    "    t_check = list_of_sims[0].t\n",
    "    for sim in list_of_sims[1:]:\n",
    "        if not np.all(t_check == sim.t):\n",
    "            same_times = False\n",
    "            break\n",
    "    return same_times\n",
    "\n",
    "\n",
    "def cross_validate(all_data:list, threshold:float, feature_library, feature_names, n_folds=10):\n",
    "    # check if list of sim objects\n",
    "    for item in all_data:\n",
    "        if not isinstance(item, ys.Yukawa_simulation):\n",
    "            raise TypeError(\"Argument 'all_data' should be list of 'Yukawa_SINDy.Yukawa_simulation' objects\")\n",
    "    # check if all time grids are the same\n",
    "    if not same_times(all_data):\n",
    "        raise Exception(\"All simulations do not have the same time grid.\")\n",
    "    \n",
    "    # extract data from sim objects\n",
    "    x_data = np.array([sim.x for sim in all_data])\n",
    "    t_data = sims[0].t\n",
    "    n_timesteps = t_data.shape[0]\n",
    "\n",
    "    # split data into withhold(testing) and training data\n",
    "    n_trajectories = len(all_data)\n",
    "    rng = np.random.default_rng(seed=10235783)\n",
    "    withhold_idxs = rng.choice(x_data.shape[0], np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "    withhold_idxs.sort()\n",
    "    train_idxs = np.delete(np.arange(len(all_data)), withhold_idxs)\n",
    "    x_train = x_data[train_idxs]\n",
    "    x_withhold = x_data[withhold_idxs]\n",
    "\n",
    "    # declare optimizer with given threshold\n",
    "    opt = ps.STLSQ(threshold=threshold)\n",
    "\n",
    "    # get number of terms in library\n",
    "    rand_data = np.random.random((5000,2))\n",
    "    test_mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "    test_mdl.fit(rand_data)\n",
    "    feature_list = test_mdl.get_feature_names()\n",
    "    n_features = len(feature_list)\n",
    "    del test_mdl, rand_data\n",
    "\n",
    "    # perform KFold CV\n",
    "    rmse_kf = []\n",
    "    all_coefs = np.empty((0,x_data.shape[2],n_features))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train, test in kf.split(train_idxs):\n",
    "        # split training data\n",
    "        x_train_kf = [traj for traj in x_train[train]]\n",
    "        x_test_kf  = [traj for traj in x_train[test]]\n",
    "        # fit SINDy model using given threshold\n",
    "        mdl = ps.SINDy(optimizer=opt, feature_library=feature_library, feature_names=feature_names)\n",
    "        mdl.fit(x_train_kf, t_data, multiple_trajectories=True)\n",
    "\n",
    "        # get coefs and append to all_coefs\n",
    "        coefs = mdl.coefficients()\n",
    "        coefs.resize((1,*coefs.shape))\n",
    "        all_coefs = np.vstack((all_coefs,coefs))\n",
    "\n",
    "        # validate model against test data\n",
    "        rmse = mdl.score(x_test_kf,t_data,multiple_trajectories=True)#,metric=root_mean_squared_error)\n",
    "        rmse_kf.append(rmse)\n",
    "        # # old code\n",
    "        # x_dot_predicted = mdl.predict(x_test_kf)\n",
    "        # fd = ps.FiniteDifference()\n",
    "        # x_dot_calculated = fd._differentiate(x_test_kf)\n",
    "        # rmse = root_mean_squared_error(x_dot_calculated, x_dot_predicted)\n",
    "        # rmse_kf.append(rmse)\n",
    "        \n",
    "\n",
    "    return x_train, x_withhold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/pysindy/optimizers/stlsq.py:191: UserWarning: Sparsity parameter is too big (0.5) and eliminated all coefficients\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m feature_library = ys.generate_Yukawa_library()\n\u001b[32m      3\u001b[39m feature_names = [\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mv\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m x_train, x_withhold = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_library\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(all_data, threshold, feature_library, feature_names, n_folds)\u001b[39m\n\u001b[32m     65\u001b[39m all_coefs = np.vstack((all_coefs,coefs))\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# validate model against test data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m rmse = \u001b[43mmdl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmultiple_trajectories\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#,metric=root_mean_squared_error)\u001b[39;00m\n\u001b[32m     69\u001b[39m rmse_kf.append(rmse)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# # old code\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# x_dot_predicted = mdl.predict(x_test_kf)\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# fd = ps.FiniteDifference()\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# x_dot_calculated = fd._differentiate(x_test_kf)\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# rmse = root_mean_squared_error(x_dot_calculated, x_dot_predicted)\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# rmse_kf.append(rmse)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/pysindy/pysindy.py:614\u001b[39m, in \u001b[36mSINDy.score\u001b[39m\u001b[34m(self, x, t, x_dot, u, multiple_trajectories, metric, **metric_kws)\u001b[39m\n\u001b[32m    609\u001b[39m     multiple_trajectories = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    610\u001b[39m x, x_dot, u = _comprehend_and_validate_inputs(\n\u001b[32m    611\u001b[39m     x, t, x_dot, u, \u001b[38;5;28mself\u001b[39m.feature_library\n\u001b[32m    612\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m x_dot_predict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple_trajectories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiple_trajectories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.discrete_time \u001b[38;5;129;01mand\u001b[39;00m x_dot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    617\u001b[39m     x_dot_predict = [xd[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xd \u001b[38;5;129;01min\u001b[39;00m x_dot_predict]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/pysindy/pysindy.py:477\u001b[39m, in \u001b[36mSINDy.predict\u001b[39m\u001b[34m(self, x, u, multiple_trajectories)\u001b[39m\n\u001b[32m    475\u001b[39m     u = validate_control_variables(x, u)\n\u001b[32m    476\u001b[39m     x = [np.concatenate((xi, ui), axis=xi.ax_coord) \u001b[38;5;28;01mfor\u001b[39;00m xi, ui \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x, u)]\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m result = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m    478\u001b[39m result = [\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_library.reshape_samples_to_spatial_grid(pred)\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[32m    481\u001b[39m ]\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Kept for backwards compatibility.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/sklearn/pipeline.py:789\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    788\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    792\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/pysindy/optimizers/sindy_optimizer.py:89\u001b[39m, in \u001b[36mSINDyOptimizer.predict\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prediction.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m prediction[:, np.newaxis]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/sklearn/linear_model/_base.py:298\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    285\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    287\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yukawa-sindy-vetted/lib/python3.12/site-packages/sklearn/linear_model/_base.py:282\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X @ coef_ + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m + \u001b[38;5;28mself\u001b[39m.intercept_\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 10)"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "feature_library = ys.generate_Yukawa_library()\n",
    "feature_names = ['x', 'v']\n",
    "\n",
    "x_train, x_withhold = cross_validate(sims, threshold, feature_library, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract data from sim objects\n",
    "x_data = np.array([sim.x for sim in sims])\n",
    "t_data = sims[0].t\n",
    "n_timesteps = t_data.shape[0]\n",
    "\n",
    "# split data into withhold(testing) and training data\n",
    "n_trajectories = len(sims)\n",
    "rng = np.random.default_rng(seed=10235783)\n",
    "withhold_idxs = rng.choice(n_trajectories, np.floor(0.25 * n_trajectories).astype(int), replace=False)\n",
    "withhold_idxs.sort()\n",
    "train_idxs = np.delete(np.arange(len(sims)), withhold_idxs)\n",
    "x_train = x_data[train_idxs]\n",
    "x_withhold = x_data[withhold_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: (150, 5000, 2), withhold: (50, 5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"training: {x_train.shape}, withhold: {x_withhold.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.41356834, 0.11340827],\n",
       "        [0.39035098, 0.34350152],\n",
       "        [0.50735309, 0.71549869],\n",
       "        ...,\n",
       "        [0.20607009, 0.78325177],\n",
       "        [0.40298175, 0.13817783],\n",
       "        [0.50899538, 0.7800266 ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp = np.empty((0,5000,2))\n",
    "append = np.random.random((5000,2))\n",
    "append.resize((1,5000,2))\n",
    "np.vstack((emp,append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (5,2)\n",
    "b = (10,*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
